{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WNBA Team Stats 2024\n",
    "\n",
    "RUN THIS PROGRAM BEFORE EACH WORKSHOP TO GET THE LATEST DATA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Program: WNBA Team Stats Scraper for 2024\n",
    "Author: Peter Beens\n",
    "Date: 2024-05-19\n",
    "Description: This program scrapes WNBA team statistics from ESPN's website for the 2024 season. It uses Selenium to extract team names and pandas to \n",
    "process the statistics tables. The final dataset is saved as a CSV file.\n",
    "Usage: Ensure that Firefox and geckodriver are installed. Run the script in an environment where these dependencies are properly configured.\n",
    "Dependencies: \n",
    "    - selenium\n",
    "    - pandas\n",
    "    - Firefox browser\n",
    "    - geckodriver (ensure it is installed and in your PATH)\n",
    "Notes: \n",
    "    - The script assumes the structure of the webpage remains constant.\n",
    "    - Modify the URL or XPath expressions if the webpage structure changes.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "# Initialize the WebDriver for Firefox. Ensure geckodriver is installed and in your PATH.\n",
    "wd = webdriver.Firefox()\n",
    "\n",
    "# Define the URL to scrape\n",
    "url = \"https://www.espn.com/wnba/stats/team/_/season/2024/seasontype/2\"\n",
    "\n",
    "# Open the URL in the WebDriver\n",
    "wd.get(url)\n",
    "\n",
    "# Extract the team names using Selenium by locating elements that match the given XPath\n",
    "team_elements = wd.find_elements(By.XPATH, \"//div[@class='ResponsiveTable ResponsiveTable--fixed-left mt4 Table2__title--remove-capitalization']//a[contains(@href, '/wnba/team/_/name/')]\")\n",
    "\n",
    "# Extract the text from each WebElement and store it in a list\n",
    "team_names = [element.text for element in team_elements if element.text]\n",
    "\n",
    "# Close the WebDriver\n",
    "wd.quit()\n",
    "\n",
    "# Print the number of team names extracted and the team names themselves for verification\n",
    "print(f\"Number of team names extracted: {len(team_names)}\")\n",
    "print(team_names)\n",
    "\n",
    "# Use pandas to read the HTML tables from the webpage source\n",
    "tables = pd.read_html(url)\n",
    "\n",
    "# Print the number of tables found on the webpage for verification\n",
    "print(f\"Number of tables found: {len(tables)}\")\n",
    "\n",
    "# Assuming the first table contains 'RK' and 'TEAM' columns, and the second table contains the rest of the statistics\n",
    "rank_team = tables[0]\n",
    "stats = tables[1]\n",
    "\n",
    "# Remove the 'RK' and 'Team' columns from the rank_team DataFrame\n",
    "rank_team = rank_team.drop(columns=['RK', 'Team'])\n",
    "\n",
    "# Add the extracted team names to the rank_team DataFrame\n",
    "rank_team['Team'] = team_names\n",
    "\n",
    "# Merge the rank_team and stats DataFrames on their index to create a complete dataset\n",
    "df = pd.concat([rank_team, stats], axis=1)\n",
    "\n",
    "# Display the final DataFrame to ensure correctness\n",
    "print(df)\n",
    "\n",
    "# Save the DataFrame to a CSV file named 'wnba_team_stats_2024.csv'\n",
    "df.to_csv('wnba_team_stats_2024.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine All Team Stats\n",
    "\n",
    "USED AFTER UPDATING DATA FROM 2024."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\"\"\"\n",
    "Program: WNBA Team Stats Aggregator\n",
    "Author: Peter\n",
    "Date: 2024-05-19\n",
    "Description: This program aggregates WNBA team statistics from multiple CSV files, each representing a year from 2007 to 2024. It reads each CSV file, \n",
    "adds a 'Year' column, and combines the data into a single DataFrame. The final DataFrame is sorted by year (descending) and team (ascending), and saved \n",
    "to a CSV file.\n",
    "Usage: Ensure that all CSV files (wnba_team_stats_YYYY.csv) are in the same directory as this script. Run the script to generate a combined CSV file \n",
    "(wnba_team_stats_all.csv) containing all the data.\n",
    "Dependencies: pandas, os\n",
    "Notes: Make sure that the CSV files follow a consistent format with the expected columns.\n",
    "\"\"\"\n",
    "\n",
    "# Initialize an empty DataFrame to hold the combined data\n",
    "combined_df = pd.DataFrame()\n",
    "\n",
    "# Loop through the years from 2007 to 2024\n",
    "for year in range(2007, 2024 + 1):\n",
    "    filename = f'wnba_team_stats_{year}.csv'\n",
    "    print(f'Processing {filename}...')\n",
    "    \n",
    "    try:\n",
    "        if os.path.exists(filename):\n",
    "            # Read the CSV file into a DataFrame\n",
    "            df = pd.read_csv(filename)\n",
    "            \n",
    "            # Add the 'Year' column\n",
    "            df['Year'] = year\n",
    "            \n",
    "            # Append the data to the combined DataFrame\n",
    "            combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
    "        else:\n",
    "            print(f'File {filename} does not exist.')\n",
    "    except Exception as e:\n",
    "        print(f'An error occurred while processing {filename}: {e}')\n",
    "\n",
    "# Sort the combined DataFrame by 'Year' (reversed) and 'Team'\n",
    "combined_df.sort_values(by=['Year', 'Team'], ascending=[False, True], inplace=True)\n",
    "\n",
    "# Reorder the columns\n",
    "ordered_columns = ['Team', 'Year', 'GP', 'PTS', 'FGM', 'FGA', 'FG%', '3PM', '3PA', '3P%', 'FTM', 'FTA', 'FT%', 'OR', 'DR', 'REB', 'AST', 'STL', 'BLK', 'TO', 'PF']\n",
    "combined_df = combined_df[ordered_columns]\n",
    "\n",
    "# Define the output file path\n",
    "output_file = 'wnba_team_stats_all.csv'\n",
    "\n",
    "# Save the combined DataFrame to a CSV file\n",
    "combined_df.to_csv(output_file, index=False)\n",
    "\n",
    "# Display a success message\n",
    "print(\"'wnba_team_stats_all.csv' created successfully.\")\n",
    "\n",
    "# Display the combined DataFrame\n",
    "print(combined_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get All Team Data (2007-2024)\n",
    "\n",
    "DO NOT USE THIS SCRIPT. ONLY USED TO INITIALLY GET ALL THE DATA. \n",
    "\n",
    "FOR UPDATED 2024 DATA, SEE BELOW."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "# Function to scrape data for a given season\n",
    "def scrape_season_data(season):\n",
    "    # Initialize the WebDriver for Firefox. Ensure geckodriver is installed and in your PATH.\n",
    "    wd = webdriver.Firefox()\n",
    "\n",
    "    # Define the URL to scrape\n",
    "    url = f\"https://www.espn.com/wnba/stats/team/_/season/{season}/seasontype/2\"\n",
    "\n",
    "    # Open the URL in the WebDriver\n",
    "    wd.get(url)\n",
    "\n",
    "    # Extract the team names using Selenium by locating elements that match the given XPath\n",
    "    team_elements = wd.find_elements(By.XPATH, \"//div[@class='ResponsiveTable ResponsiveTable--fixed-left mt4 Table2__title--remove-capitalization']//a[contains(@href, '/wnba/team/_/name/')]\")\n",
    "    # Extract the text from each WebElement and store it in a list\n",
    "    team_names = [element.text for element in team_elements if element.text]\n",
    "\n",
    "    # Close the WebDriver\n",
    "    wd.quit()\n",
    "\n",
    "    # Print the number of team names extracted and the team names themselves for verification\n",
    "    print(f\"Season {season}: Number of team names extracted: {len(team_names)}\")\n",
    "    # print(team_names)\n",
    "\n",
    "    # Use pandas to read the HTML tables from the webpage source\n",
    "    tables = pd.read_html(url)\n",
    "\n",
    "    # Print the number of tables found on the webpage for verification\n",
    "    # print(f\"Season {season}: Number of tables found: {len(tables)}\")\n",
    "\n",
    "    # Assuming the first table contains 'RK' and 'TEAM' columns, and the second table contains the rest of the statistics\n",
    "    rank_team = tables[0]\n",
    "    stats = tables[1]\n",
    "\n",
    "    # Remove the 'RK' and 'Team' columns from the rank_team DataFrame\n",
    "    rank_team = rank_team.drop(columns=['RK', 'Team'])\n",
    "    # Add the extracted team names to the rank_team DataFrame\n",
    "    rank_team['Team'] = team_names\n",
    "\n",
    "    # Merge the rank_team and stats DataFrames on their index to create a complete dataset\n",
    "    df = pd.concat([rank_team, stats], axis=1)\n",
    "\n",
    "    # Save the DataFrame to a CSV file named f'wnba_team_stats_{season}.csv'\n",
    "    df.to_csv(f'wnba_team_stats_{season}.csv', index=False)\n",
    "\n",
    "# Loop over the range of seasons from 2007 to 2024\n",
    "for season in range(2007, 2025):\n",
    "    scrape_season_data(season)\n",
    "    # Wait for a few seconds to avoid overloading the server\n",
    "    time.sleep(5)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
