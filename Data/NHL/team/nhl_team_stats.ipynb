{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WNBA Team Stats 2024\n",
    "\n",
    "RUN THIS PROGRAM BEFORE EACH WORKSHOP TO GET THE LATEST DATA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Scraping season 2024-2025...\n",
      "✅ Extracted 32 teams for 2024-2025.\n",
      "✅ Data successfully saved to nhl_team_stats_2024-2025.csv\n",
      "🎉 Scraping complete!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# Set the target season\n",
    "end_year = 2025\n",
    "start_year = end_year - 1\n",
    "\n",
    "# Construct URL and filename\n",
    "url = f\"https://www.espn.com/nhl/stats/team/_/season/{end_year}/seasontype/2\"\n",
    "filename = f'nhl_team_stats_{start_year}-{end_year}.csv'\n",
    "\n",
    "print(f\"🔄 Scraping season {start_year}-{end_year}...\")\n",
    "\n",
    "# Set up Selenium options to mimic a real user\n",
    "options = Options()\n",
    "options.set_preference(\n",
    "    \"general.useragent.override\",\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36\"\n",
    ")\n",
    "\n",
    "# Initialize WebDriver\n",
    "wd = webdriver.Firefox(options=options)\n",
    "wd.get(url)\n",
    "\n",
    "try:\n",
    "    # Wait for elements to load\n",
    "    WebDriverWait(wd, 10).until(\n",
    "        EC.presence_of_all_elements_located((By.XPATH, \"//a[contains(@href, '/nhl/team/_/name/')]\"))\n",
    "    )\n",
    "\n",
    "    # Extract team names\n",
    "    team_elements = wd.find_elements(By.XPATH, \"//a[contains(@href, '/nhl/team/_/name/')]\")\n",
    "    team_names = [element.text for element in team_elements if element.text]\n",
    "\n",
    "    if not team_names:\n",
    "        print(f\"⚠ Warning: No team names found for {start_year}-{end_year}. Exiting...\")\n",
    "        wd.quit()\n",
    "        exit()\n",
    "\n",
    "    print(f\"✅ Extracted {len(team_names)} teams for {start_year}-{end_year}.\")\n",
    "\n",
    "    # Read tables from the page\n",
    "    tables = pd.read_html(url)\n",
    "\n",
    "    if len(tables) < 2:\n",
    "        print(f\"⚠ Error: Expected tables not found for {start_year}-{end_year}. Exiting...\")\n",
    "        wd.quit()\n",
    "        exit()\n",
    "\n",
    "    # Process table data\n",
    "    rank_team = tables[0]\n",
    "    stats = tables[1]\n",
    "\n",
    "    # Remove the 'RK' and 'Team' columns from rank_team\n",
    "    rank_team = rank_team.drop(columns=['RK', 'Team'], errors='ignore')  # Ignore missing columns\n",
    "\n",
    "    # Ensure team names list matches row count\n",
    "    if len(rank_team) != len(team_names):\n",
    "        print(f\"⚠ Mismatch: Expected {len(rank_team)} teams, but got {len(team_names)}.\")\n",
    "        wd.quit()\n",
    "        exit()\n",
    "\n",
    "    # Add team names\n",
    "    rank_team['Team'] = team_names\n",
    "\n",
    "    # Merge data\n",
    "    df = pd.concat([rank_team, stats], axis=1)\n",
    "\n",
    "    # Save to CSV in the same directory as the script\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(f\"✅ Data successfully saved to {filename}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error processing season {start_year}-{end_year}: {e}\")\n",
    "\n",
    "finally:\n",
    "    wd.quit()  # Close WebDriver\n",
    "\n",
    "print(\"🎉 Scraping complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine All Team Stats\n",
    "\n",
    "USED AFTER UPDATING DATA FROM 2024."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\"\"\"\n",
    "Program: WNBA Team Stats Aggregator\n",
    "Author: Peter\n",
    "Date: 2024-05-19\n",
    "Description: This program aggregates WNBA team statistics from multiple CSV files, each representing a year from 2007 to 2024. It reads each CSV file, \n",
    "adds a 'Year' column, and combines the data into a single DataFrame. The final DataFrame is sorted by year (descending) and team (ascending), and saved \n",
    "to a CSV file.\n",
    "Usage: Ensure that all CSV files (wnba_team_stats_YYYY.csv) are in the same directory as this script. Run the script to generate a combined CSV file \n",
    "(wnba_team_stats_all.csv) containing all the data.\n",
    "Dependencies: pandas, os\n",
    "Notes: Make sure that the CSV files follow a consistent format with the expected columns.\n",
    "\"\"\"\n",
    "\n",
    "# Initialize an empty DataFrame to hold the combined data\n",
    "combined_df = pd.DataFrame()\n",
    "\n",
    "# Loop through the years from 2007 to 2024\n",
    "for year in range(2007, 2024 + 1):\n",
    "    filename = f'wnba_team_stats_{year}.csv'\n",
    "    print(f'Processing {filename}...')\n",
    "    \n",
    "    try:\n",
    "        if os.path.exists(filename):\n",
    "            # Read the CSV file into a DataFrame\n",
    "            df = pd.read_csv(filename)\n",
    "            \n",
    "            # Add the 'Year' column\n",
    "            df['Year'] = year\n",
    "            \n",
    "            # Append the data to the combined DataFrame\n",
    "            combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
    "        else:\n",
    "            print(f'File {filename} does not exist.')\n",
    "    except Exception as e:\n",
    "        print(f'An error occurred while processing {filename}: {e}')\n",
    "\n",
    "# Sort the combined DataFrame by 'Year' (reversed) and 'Team'\n",
    "combined_df.sort_values(by=['Year', 'Team'], ascending=[False, True], inplace=True)\n",
    "\n",
    "# Reorder the columns\n",
    "ordered_columns = ['Team', 'Year', 'GP', 'PTS', 'FGM', 'FGA', 'FG%', '3PM', '3PA', '3P%', 'FTM', 'FTA', 'FT%', 'OR', 'DR', 'REB', 'AST', 'STL', 'BLK', 'TO', 'PF']\n",
    "combined_df = combined_df[ordered_columns]\n",
    "\n",
    "# Define the output file path\n",
    "output_file = 'wnba_team_stats_all.csv'\n",
    "\n",
    "# Save the combined DataFrame to a CSV file\n",
    "combined_df.to_csv(output_file, index=False)\n",
    "\n",
    "# Display a success message\n",
    "print(\"'wnba_team_stats_all.csv' created successfully.\")\n",
    "\n",
    "# Display the combined DataFrame\n",
    "print(combined_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get All Team Data (2007-2024)\n",
    "\n",
    "DO NOT USE THIS SCRIPT. ONLY USED TO INITIALLY GET ALL THE DATA. \n",
    "\n",
    "FOR UPDATED 2024 DATA, SEE BELOW."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "# Function to scrape data for a given season\n",
    "def scrape_season_data(season):\n",
    "    # Initialize the WebDriver for Firefox. Ensure geckodriver is installed and in your PATH.\n",
    "    wd = webdriver.Firefox()\n",
    "\n",
    "    # Define the URL to scrape\n",
    "    url = f\"https://www.espn.com/wnba/stats/team/_/season/{season}/seasontype/2\"\n",
    "\n",
    "    # Open the URL in the WebDriver\n",
    "    wd.get(url)\n",
    "\n",
    "    # Extract the team names using Selenium by locating elements that match the given XPath\n",
    "    team_elements = wd.find_elements(By.XPATH, \"//div[@class='ResponsiveTable ResponsiveTable--fixed-left mt4 Table2__title--remove-capitalization']//a[contains(@href, '/wnba/team/_/name/')]\")\n",
    "    # Extract the text from each WebElement and store it in a list\n",
    "    team_names = [element.text for element in team_elements if element.text]\n",
    "\n",
    "    # Close the WebDriver\n",
    "    wd.quit()\n",
    "\n",
    "    # Print the number of team names extracted and the team names themselves for verification\n",
    "    print(f\"Season {season}: Number of team names extracted: {len(team_names)}\")\n",
    "    # print(team_names)\n",
    "\n",
    "    # Use pandas to read the HTML tables from the webpage source\n",
    "    tables = pd.read_html(url)\n",
    "\n",
    "    # Print the number of tables found on the webpage for verification\n",
    "    # print(f\"Season {season}: Number of tables found: {len(tables)}\")\n",
    "\n",
    "    # Assuming the first table contains 'RK' and 'TEAM' columns, and the second table contains the rest of the statistics\n",
    "    rank_team = tables[0]\n",
    "    stats = tables[1]\n",
    "\n",
    "    # Remove the 'RK' and 'Team' columns from the rank_team DataFrame\n",
    "    rank_team = rank_team.drop(columns=['RK', 'Team'])\n",
    "    # Add the extracted team names to the rank_team DataFrame\n",
    "    rank_team['Team'] = team_names\n",
    "\n",
    "    # Merge the rank_team and stats DataFrames on their index to create a complete dataset\n",
    "    df = pd.concat([rank_team, stats], axis=1)\n",
    "\n",
    "    # Save the DataFrame to a CSV file named f'wnba_team_stats_{season}.csv'\n",
    "    df.to_csv(f'wnba_team_stats_{season}.csv', index=False)\n",
    "\n",
    "# Loop over the range of seasons from 2007 to 2024\n",
    "for season in range(2007, 2025):\n",
    "    scrape_season_data(season)\n",
    "    # Wait for a few seconds to avoid overloading the server\n",
    "    time.sleep(5)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
